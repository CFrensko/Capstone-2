{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project 2: Lending Club Final Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DESCRIPTIVE ABSTRACT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is your first time using the peer to peer platform Lending Club and you are looking to invest in a portfolio of loans with the highest rate of return. How do you know which loans to choose? What is the chance that the loan will go into default or get paid off? This report will explore the features of approved loans and create a model to predict the possibility of default.\n",
    "\n",
    "The data used is from 2015-2016 that consists of 421,097 rows with 145 columns. The data is taken from: https://www.lendingclub.com/info/download-data.action\n",
    "\n",
    "I will first apply data wrangling to clean up the data. Next I will do exploratory analysis by applying inferential statistics to better understand the data correlations and variables. After I will build a baseline model using logistic regression with hyper-parameter tuning using L1 and L2 regularization (regularization parameter). \n",
    "\n",
    "I will split the data into a training and test set to assess the performance of this model’s accuracy, precision, recall, specificity and F1 score. This will determine whether I should further explore other models such as random forest, KNN or decision tree. These results will all be tied together to see the impact each factor may have on overall price. The deliverables for this project will be the code and this report detailing the work completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lending Club is a peer to peer lending platform for loans up to $40,000. They were established in 2007 as a new way to provide credit with lower interest rates. A new customer can be approved in as little as 7 days with a payback period of 36 or 60 months. It offers investors access to the consumer credit asset class with the ability to make 3-8 percent returns. As lenders pay back their loan the ‘Lending Club Note’ investors receive monthly payments of both the principal and interest. If you invested in a bond you would not receive your principal back till maturity. \n",
    "\n",
    "The problem being solved is to identify whether the loan will be paid or go into default using a binary classification machine learning method. The client for this problem is Lending Club’s investors, the users lending money for the loans. This solution is important to identify for the client because the client needs a strong analysis and model for how the loans are predicted to perform. This will help the client determine which loan or group of loans to invest in based on their personal risk tolerance. We will need to identify how different loans do over time and determine a reasonable probability that a loan will default. We can use the approved loan features as support for Lending Club’s decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 APPROACH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach for solving this problem was to first apply data wrangling to clean up the data. Next do exploratory analysis by applying inferential statistics to better understand the data correlations and variables. Afterwards to build a baseline model using logistic regression with hyper-parameter tuning using L1 and L2 regularization (regularization parameter).\n",
    "\n",
    "Next the data was split into a training and test set to assess the performance of this model’s accuracy, precision, recall, specificity and F1 score. Later the data was further explored using logistic regression and  random forest. These results were tied together to see the impact each factor may have on defaulted loans. The deliverables for this project is the code and this report detailing the work completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DATA SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 DATA ACQUISITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used was pulled from lending club's website under lending club statistics for the year 2015-2016. The data was downloaded as a csv file and read as one large dataframe totaling 421,097 rows with 145 columns. Shown below is the distribution of loan amount by quantity and cost. The \n",
    "website the data was taken from: https://www.lendingclub.com/info/download-data.action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Distribution of Loan Amount Image](/Images/Distribution of Loan Amount.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2  DATA CLEANING & EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I began by performing exploratory data analysis to catch any discrepancies that would impact the model. I removed a multitude of columns that contained greater than 50% of missing data including: id, member_id, emp_title, url, desc, next_pymnt_d, mths_since_last_major_derog, mths_since_last_record, mths_since_recent_bc_dlq, mths_since_recent_revol_delinq, sec_app_open_acc, sec_app_revol_util, sec_app_open_act_il, sec_app_num_rev_accts, sec_app_chargeoff_within_12_mths, sec_app_collections_12_mths_ex_med, sec_app_mths_since_last_major_derog, hardship_type, hardship_reason, hardship_status, deferral_term, hardship_amount, hardship_start_date, hardship_end_date, payment_plan_start_date, hardship_length, hardship_dpd, mths_since_last_delinq, hardship_loan_status, orig_projected_additional_accrued_interest, hardship_payoff_balance_amount, hardship_last_payment_amount, debt_settlement_flag_date, settlement_status, settlement_date, settlement_amount, settlement_percentage, settlement_term, revol_bal_joint, sec_app_earliest_cr_line, sec_app_inq_last_6mths, open_acc_6m, open_act_il, open_il_12m, open_il_24m, mths_since_rcnt_il, il_util, open_rv_12m, open_rv_24m, max_bal_bc, total_bal_il, all_util, inq_fi, total_cu_tl, inq_last_12m, sec_app_mort_acc, annual_inc_joint, dti_joint, and verification_status_joint. \n",
    "\n",
    "After reviewing the data available I came up with a subset of data useful for the analysis. I created a new dataframe labeled approved to further clean and perform logistic regression with. These categories included: grade, emp_length, home_ownership, verification_status, loan_status and term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Loan Status (Target Variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the loan status as the target variable for the logistic regression model and narrowed it down into two categories of good loan and bad loan. A good loan is a loan in good status. This would include those that are fully paid or current on their payments. A bad loan is one that has gone bad with little possibility of being reversed. This includes a charged off loan (categorized as severely deliquent with little possibility of being paid off) or a defaulted loan. Those loans in the late or grace period categories were removed because these loans could become a good or bad loan over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Loan Distribution by Loan Status All Image](/Images/Loan Distribution by Loan Status All.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Loan Status Image](/Images/Loan Status.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I labeled 'Good Loans', loans that are paid off or current with payments with a '1'. Those labeled as 'Bad Loans' or '0' are those that are in the charged off or in default status. The other categories of late or in grace period were removed. Below you can see that there are about 3.5 times more good loans (245493) than bad loans (69397)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Loan Distribution by Loan Status All Image](/Images/Loan Distribution by Loan Status.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A total of 15.54 percent of the loans are bad loans & non-verified while 24.47 percent of the loans are bad loans & verified. While 84.46 percent of the loans are good loans & non-verified and 75.53 percent are good loans and verified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Verification Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The verification status indicates if income was verified by Lending Club, not verified, or if the income source was verified. I merged all those verified into one category labeled 1 and put all those unverified as 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Distribution of Verification Status Image](/Images/Distribution of Verification Status.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Distribution of Verification Status Pie Chart Image](/Images/Distribution of Verification Status Pie Chart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I created a stacked bar chart to look at the comparison of verified loans vs. good/bad loan status. A total of 15.54% of the loans were bad loans & non-verified while 24.47% of the loans were bad loans & verified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Verification by loan status Image](/Images/Verification by loan status.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Loan Grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are seven loan categories A to G. A is rated as the highest quality with G as the worst. First I looked at the loan grades vs loan amounts. There appeared to be many more loans approved for categories A-D than E-G."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Loan grades vs loan amounts Image](/Images/Loan grades vs loan amounts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Loan Grades Image](/Images/Loan Grades.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I next sorted the grades into numerical categories and compared them to the loan status. Loans categorized A (labeled 1) to C (labeled 3) have a low level of being a bad loan while D-G (labeled 4-7) have a higher chance of being a bad loan. The percentage of bad loans for each category were: '1':6.3%,'2':14.7%,'3':24.1%,'4':33.8%,'5':42.4%,'6':51.3%,'7':53.45%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Loan status vs loan grade Image](/Images/Loan status vs loan grade.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Home Ownership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The home ownership status was provided by the borrower during registration or obtained from the credit report. These values are: RENT, OWN, MORTGAGE, OTHER. I separated them into two categories of 1 signifying own/mortgage and 0 showing it is rent/any."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Loan Distribution by Home Ownership Image](/Images/Loan Distribution by Home Ownership.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Home Ownership Image](/Images/Home Ownership.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then created a stacked bar graph to compare home ownership to the loan status. There was a total of 25.5% bad loans in the rent/any category and 19.66% bad loans in the mortgage/own category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Home Ownership vs Loan Status Image](/Images/Home Ownership vs Loan Status.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.5 Employment Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Employment length is listed in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years. In order to clean up the variables I changed 'n/a' to Nan. Since this category nan appears to be employment that isn't specified or those unemployed did not list years of employment, I replaced it with 0.\n",
    "\n",
    "To further clean I replaced the < (less than) sign with a space for less than one year. To simplify the categories I also combined less than a year with one year. Employment length was then sorted into 11 categories and I compared it to the target value of loan status. There was not any significant visible increase of default based on years of employment in the approved loans. The percentage of bad loans in each year stayed about 22% of the total loan except year zero with a total of 28.87 percent bad loans. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Employment Length Distribution.Image](/Images/Employment Length Distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Employment length vs loan status.Image](/Images/Employment length vs loan status.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.6 Term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term is the number of payments on the loan. Values are in months and can be either 36 or 60. I separated and categorized the 36 month loans as 1 and the 60 month loans as 0. I then compared them to the loan status as good or bad. There was a significant larger number of defaults/Charge offs in the 60 month term vs the 36 month term. A total of 36.57% of the 60 month loans were bad loans while 17% of the 36 month loans were bad loans. Considering many more loans were approved for 36 month term periods this may be an indicator of a good vs bad loan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Term vs loan status.Image](/Images/Term vs loan status.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Terms Counts.Image](/Images/Terms Counts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.7 Dummy Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then created dummy variables for all of the categories, this lists all variables as 1 or 0 to prepare for the logistic regression model. The new data consists of 314890 rows and 25 columns. The dataframes were then saved as csvs for easy access for future models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data wrangling is given without the complete Python code for my project. This can be found on my github: https://github.com/CFrensko/Capstone-2/blob/master/Capstone%20Project%202%20Lending%20Club%20Data%20Cleaning.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. INFERENTIAL STATISTICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end goal of performing a hypothesis test was to evaluate the variability of home ownership within the different loan status' in this data set. To see if there was significant variability between the two independent features in the data set. The two sample test was applied to compare whether the average difference between the two groups was significant or if it was due instead to random chance. \n",
    "\n",
    "In this scenario since there was a large sample size with a binomial population ('1' and '0') but the standard deviation was unknown, we used a 2-sample t-test. With the large data set (>30) we can assume the means are normally distributed across the sample and the central limit theorem applies to this problem.\n",
    "\n",
    "In the dataset provided, each row represents a loan. The 'loan status separated' column has two values, '1' and '0', indicating good loan(paid/current) and bad loan (charged off/default). The column 'home ownership' has 2 values, 1 and 0, indicating whether the person taking the loan owns their home (1 being a homeowner 0 being a renter or other). The end goal was to evaluate if loan status impacts the home ownership in this collected sample.\n",
    "\n",
    "The Null Hypothesis: Approved Good and Bad loans have the same home ownership values.\n",
    "The Alternative Hypothesis: Approved Good and Bad loans have different home ownership values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Compute margin of error, confidence interval and p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analysis on this data set it appears that home ownership had a significant value difference in good vs bad loans. The results from the tests show that the percentage of home ownership for good_loans was 61.17 percent and the percentage of home ownership for bad loans was 52.96 percent. The difference in percentage of home ownership is 8.2 percent.\n",
    "\n",
    "The t-statistic measures the size of the difference relative to the variation in the data. For this case the t-statistic was 38.5 with a p-value of zero. This means that the decision would be to reject the null hypothesis that the good and bad loans have the same ownership values. Also that the difference between the means of the test are statistically significant. In fact it is 38.5 times the ratio of the departure of the estimated value of a parameter from its hypothesized value to its standard error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Compute margin of error, confidence interval and p-value.Image](/Images/Compute margin of error, confidence interval and p-value.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Frequentist Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We performed a few tests to see if this difference could be perceived as random using a 2 sample t-test and frequentist bootstrapping. The p-value for the t-test and bootstrapping are both 0 so we can reject the null hypothesis. \n",
    "\n",
    "This means loan status is impacted by home ownership in this collected sample. There are however other variables (verification, grade, employment length, term) in the study that also should be taken into consideration in further investigation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Frequentist Bootstrapping.Image](/Images/Frequentist Bootstrapping.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inferential statistics is given without the complete Python code for my project. This can be found on my github: https://github.com/CFrensko/Capstone-2/blob/master/Capstone%20Project%202%20Lending%20Club%20Inferential%20Statistics.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the dataset is clean with the features free of excess noise I used supervised machine learning algorithms to build a predictive model. I first used logistic regression to classify and analyze the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The cleaned data was separated into a 80% training and 20% test set and the training data. It was then fit to the logistic regression model to predict loan status. The accuracy of logistic regression classifier on the test set was 0.78311. At first glance this appears to be a good prediction but the results still needs further analysis.\n",
    "\n",
    "Next I tuned the model with 10 fold cross validation. Cross-validation is a technique used to evaluate the model by partitioning the original data set into training and test sets. In k-fold cross-validation such as this, the original sample was randomly partitioned into k equal size subsamples. The average accuracy was very close to the logistic regression classifier so it can be concluded that the model generalizes well.\n",
    "\n",
    "Next I used a grid of parameters to select the best feature c. The best regularization parameter for c was 10 (although 1 and 100 came in close). The purpose for this parameter is to tune unlikely high regression coefficients, preventing features from having terribly high weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Best C Values.Image](/Images/Best C Values.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the parameter of c = 10 was applied to the model it actually performed worse. Since this was only fit on one set of data I used cross-validation and grid search to test several other sets of training data to further test for the optimal c parameter to use for the test set. The best parameter chosen when testing on multiple data sets was 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most performance metrics for the logistic regression model are based on the confusion matrix. It describes the number of true postives in the top left, true negatives in the bottom right, false positives in the top right and false negatives in the bottom left. True negatives and true positives are as they sound, that the values that were true or false were correctly identified/classified. False negatives and positives mean they were misclassified.\n",
    "At first glance the false positives and negatives look high, I will use the next section to explain this significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Confusion Matrix.Image](/Images/Confusion Matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Precision, Recall, F-Measure & Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision tells what percent described as defaulted or paid were calculated out of those predicted to be defaulted or paid. For example this takes the true positive divided by the true positive and false positive. In this case the precision is 0.79 precise for paid but only 0.53 for defaulted. This means it is more precise for predicting paid loans that were expected by the model to be paid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall or sensitivity tells what portion of those that defaulted or were paid were actually shown with the model as defaulted or paid. For example it takes the true positive divided by the true positive and false negative. The recall for those paid is 98 percent but for those that defaulted it is 10 percent. This shows an error in our model. The model does not predict well what we are looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f-measure tries to take on a harmonic mean between the precision and recall score to create one value to represent both and create a red flag if the model is not performing well. This gives us 88 percent for paid and 16 percent for defaulted. This supports our findings above that the model does not do well representing defaulted loans. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The support is the number of occurrences of each class in the test set. The number of instances of defaulted loans was 13822 and the number of paid loans was 49156 in the test set. This shows there is a large difference in instances of each for classification with an almost 1:3 ratio.  This suggests this is an imbalanced classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Precision, Recall, F-Measure & Support.Image](/Images/Precision, Recall, F-Measure & Support.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC value lies between 0.5 to 1 where 0.5 denotes a bad classifer and 1 denotes an excellent classifier. The area under the curve was 0.54 which is extremely close to 0.5. When AUC is approximately 0.5, the model has no discriminating capacity and is a poor model. This again shows this is an imbalanced classification problem and the model needs to be adjusted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ROC Curve.Image](/Images/ROC Curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Hyperparameter Tuning with Regularization Parameter (L1 & L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 and L2 regularization are techniques used to reduce model overfitting. Overfitting is when a model is trained too much. It results in weights that fit the training data really well and when this model is applied to a new dataset it will result in a poor prediction.\n",
    "\n",
    "When training a model the measure of error helps determine the right weights. Mean squared error is commonly used by finding the sum of squared differences between the output values for a set of weight values and the known, and divide by the sum of the number of training items. The idea of regularization is to penalize weight values by adding those weight values to the calculation of the error term.\n",
    "\n",
    "L1 weight regularization penalizes weight values by adding the sum of their absolute values to the error term. E = Sum(o - t)^2 / n + Sum(Abs(w))\n",
    "\n",
    "L2 weight regularization penalizes weight values by adding the sum of their squared values to the error term. E = Sum(o - t)^2 / n + Sum(w^2)\n",
    "\n",
    "When applying the penalty of L1 and L2 to the logistic regression there were no differences in the accuracy or F1 scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modeling is given without the complete Python code for my project. This can be found on my github: https://github.com/CFrensko/Capstone-2/blob/master/Capstone%20Project%202%20Lending%20Club%20Logistic%20Regression.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Improvement Summary: Imbalanced Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "One of the problems with the data set is that it is highly imbalanced with a 1:3 ratio. In this section I experimented with both under and oversampling techniques paired with both logistic regression and random forest modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 6.1 Random OverSampling with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fight the issue of imbalance one method is to generate new samples in the classes which are under-represented. One of the most naive strategies is to generate new samples by randomly sampling with replacement the current available samples. I started out with a training data set of [(0, 55575), (1, 196337)] and used random oversampling to generate new resampled data set [(0, 196337), (1, 196337)]. This resampled data was then used to fit to the logistic regression classifier model and to generate a prediction of the test set.\n",
    "\n",
    "When comparing the results to not using oversampling, the recall and F1 scores were overall much better for the combination of defaulted vs. paid loans. The score for paid loans was worse. This is okay because the model performed better because it is not generalizing or just assuming all loans are paid, leaving the small number of defaulted loans not accounted for. \n",
    "\n",
    "Precision which tells what percent described as defaulted or paid were actually defaulted or paid is better for the paid loans with 88 percent compared to 34 percent of the defaulted. Compared to using just logistic regression the precision is worse with 34 percent compared to 53 percent. Recall tells what portion of those defaulted or paid, were actually shown with the model as defaulted or paid is much higher at 68 percent compared to the original 10 percent. The F1 score which is basically an overall average of these two signifiers was a small bit worse with a overall score of 72 percent to 67 percent (with defaulted improved and paid worse)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Random Over-Sampling Logistic Regresion.Image](/Images/Random Over-Sampling Logistic Regresion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ROC Random Over-Sampling Logistic Regresion.Image](/Images/ROC Random Over-Sampling Logistic Regresion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 6.2 Synthetic Minority Oversampling Technique (SMOTE) with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the RandomOverSampler is oversampling by duplicating some of the original samples of the minority class, SMOTE generates new samples in by interpolation (adding data of a different nature than the original). Smote focuses on generating samples next to the original samples using a k-Nearest Neighbors classifier. I started out with a training data set of [(0, 55575), (1, 96337)] ), and used random oversampling to generate our new resampled data set [(0, 196337), (1, 196337)]. This resampled data will then be used to fit to the logistic regression classifier model and to generate a prediction of the test set.\n",
    "\n",
    "I ended up getting the exact same results using SMOTE as Random Over Sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###  6.3 Random Undersampling with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Under-Sampler is a fast and easy way to balance the data by randomly selecting a subset of data for the targeted classes. The original training data set was [(0, 55575), (1, 196337)] and after random under-sampling the resampled data set was [(0, 55575), (1, 55575)]. This resampled data will then be used to fit to the logistic regression classifier model and to generate a prediction of the test set.\n",
    "\n",
    "I ended up getting almost the exact same results as SMOTE & Random Over Sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Random Oversampling with Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score for random oversampling with random forest was about 65%. The precision, recall and F1 scores were very close to random oversampling with logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Over-sampling with Random Forest.Image](/Images/Over-sampling with Random Forest.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Synthetic Minority Oversampling Technique (SMOTE) with Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score for SMOTE with random forest was about 65%. The precision, recall and F1 scores were very close to SMOTE with logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SMOTE with Random Forest.Image](/Images/SMOTE with Random Forest.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  6.6 Random Under-Sampling with Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score for random under-sampling with random forest was about 64%. The precision, recall and F1 scores were very close to random under-sampling with logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Random Under-Sampling with Random Forest.Image](/Images/Random Under-Sampling with Random Forest.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imbalanced regression is given without the complete Python code for my project. This can be found on my github: https://github.com/CFrensko/Capstone-2/blob/master/Capstone%20Project%202%20Imbalanced%20Regression.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. CONCLUSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The problem being solved was to identify whether the loan will be paid or go into default using a binary classification machine learning method. The results may be summarized as follows:\n",
    "* Determining the outcome for loans is always difficult with inherently imbalanced set(1:3 ratio). By using the clean data set with the features grade, employment length, home ownership, verification status of income, loan status and term I came up with a reasonable model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logistic Regression Results.Image](/Images/Logistic Regression Results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Random Forest Results.Image](/Images/Random Forest Results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The best binary classification method for this imbalanced data set comparing the average F1 score was the Random Forest with Random Oversampling model by the smallest fraction.\n",
    "* The F1 score for this model's defaulted loans (0) was 45 percent and for the paid loans (1) was 74 percent. These results are better than just using random forest (0: 13 percent, 1: 88 percent). This means the model catches almost half of the approved loans that end up defaulting. \n",
    "* However there is still much room for improvement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 FUTURE WORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Since the focus of this work is to not only predict the defaulted loans for Lending Club's approved loans but also to understand how to improve the model for the sake of investing, more research is needed. In particular:\n",
    "* To further improve the model I would recommend using all the data of approved loans that lending club offers on its website from 2007-2018 to gather a larger more robust set of data.\n",
    "* It would also be helpful to evaluate other features in the set that would help improve the model such as debt to income ratio, employment title, or credit score (credit score was removed to be available as a public data set) in the next analysis.\n",
    "* Another variation that could be used would be to create a multi-variable classification model. Instead of just using the binary defaulted or paid categories we could also include current, in late payment or those in-grace period status.\n",
    "* This model can then be scaled to do future predictions on approved loans to evaluate the investment potential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 CLIENT RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Once these improvement have been made, the model can be used to generate an even more accurate prediction of defaulted loans for Lending Club's approved loans.\n",
    "\n",
    "* The overall recall of the best model was 65 percent. Recall or sensitivity tells us what portion of those that defaulted or were paid were actually shown with the model as defaulted or paid. For example it takes the true positive divided by the true positive and false negative. The recall for those paid was 64 percent and defaulted was 67 percent. This means that out of the minority class, the defaulted loans, 67 percent of those that actually defaulted were identified correctly.\n",
    "\n",
    " Clients should therefore always look at the short list of loans flagged as defaulted loans and have someone take a closer look at them. False negatives in this case are loans that are flagged as defaulted but should be approved as loans that will be paid (type I error). False positives are loans that are flagged as loans that will be paid but should actually be flagged as loans that will default (type II error). The likelihood of false positives is lower than false negatives due to the fact there is a 1 to 3 ratio of unpaid to paid loans.\n",
    "\n",
    " Therefore this data should be carefully reviewed by qualified staff before making final decisions on loans flagged as defaulted loans. Otherwise the risk for false negative errors will be higher and could cause the company to lose out on revenue by not approving loans that will be paid out.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ACKNOWLEDGEMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special thanks to Springboard & my mentor AJ Sanchez! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
